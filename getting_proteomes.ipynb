{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNV6KiIr+71/MFK0EMfRnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alibekk93/IDP_analysis/blob/RAPID/getting_proteomes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting UniProt proteomes for Tempura species"
      ],
      "metadata": {
        "id": "gCrzBW06JRvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "W0xJmhROJXUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install BIO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LqXxeeZXAti",
        "outputId": "0d9dd588-6dbe-4514-f057-f3e1292bf27e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: BIO in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/dist-packages (from BIO) (1.81)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from BIO) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from BIO) (4.66.1)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.10/dist-packages (from BIO) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from BIO) (1.5.3)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from BIO) (1.8.0)\n",
            "Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.10/dist-packages (from BIO) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->BIO) (1.23.5)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from mygene->BIO) (0.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BIO) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BIO) (2023.3.post1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->BIO) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->BIO) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->BIO) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->BIO) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->BIO) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->BIO) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->BIO) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install toytree toyplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G673R7xz-Kih",
        "outputId": "a4b6bfb0-564f-405b-c1ff-90abf2f5cfe2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: toytree in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: toyplot in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from toytree) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from toytree) (2.31.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from toytree) (0.18.3)\n",
            "Requirement already satisfied: arrow>=1.0 in /usr/local/lib/python3.10/dist-packages (from toyplot) (1.3.0)\n",
            "Requirement already satisfied: custom-inherit in /usr/local/lib/python3.10/dist-packages (from toyplot) (2.4.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from toyplot) (1.0.0)\n",
            "Requirement already satisfied: pypng in /usr/local/lib/python3.10/dist-packages (from toyplot) (0.20220715.0)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.10/dist-packages (from toyplot) (4.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow>=1.0->toyplot) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=1.0->toyplot) (2.8.19.14)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab->toyplot) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->toytree) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->toytree) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->toytree) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->toytree) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow>=1.0->toyplot) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qwA-LYi0wMXn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from Bio import SeqIO\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Read fasta ###\n",
        "\n",
        "def read_fasta(fasta_file: str) -> pd.DataFrame:\n",
        "  \"\"\"Processes raw .fasta files\n",
        "\n",
        "  Opens a .fasta file, parses the sequences and their IDs into a\n",
        "  dataframe and returns the dataframe.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fasta_file : str\n",
        "    the raw .fasta file directory.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pd.DataFrame\n",
        "    a dataframe with ID, Sequence and Length columns.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # open the file\n",
        "  handle = open(fasta_file, 'r')\n",
        "  seq_list = list(SeqIO.parse(handle, 'fasta'))\n",
        "  handle.close()\n",
        "\n",
        "  # parse data into lists\n",
        "  ids = [seq_record.id.split('|')[1] for seq_record in seq_list]\n",
        "  seqs = [str(seq_record.seq) for seq_record in seq_list]\n",
        "  lens = [len(seq) for seq in seqs]\n",
        "\n",
        "  # save data into a dataframe\n",
        "  df = pd.DataFrame({'ID':ids, 'Sequence':seqs, 'Length':lens})\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "M5CWrRK1yd2b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tempura dataset"
      ],
      "metadata": {
        "id": "OrTQK2xtJqDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tempura = pd.read_csv('/content/200617_TEMPURA.csv')\n",
        "# tempura = pd.read_csv('/content/tempura_bacteria_uniprot.csv', index_col=0)\n",
        "tempura = pd.read_csv('/content/tempura_filtered.csv', index_col=0)"
      ],
      "metadata": {
        "id": "HBbhsf-WxBFD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only keeping bacteria with available assembly or accession numbers"
      ],
      "metadata": {
        "id": "f74pkmUeJfVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tempura = tempura[tempura['superkingdom']=='Bacteria']\n",
        "# tempura.dropna(subset='assembly_or_accession', inplace=True)\n",
        "# tempura.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Z8qouNgexBbA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading all_proteins"
      ],
      "metadata": {
        "id": "GWPvkryzFMaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all_proteins = pd.read_csv('/content/all_proteins.csv', index_col=0)\n",
        "# all_proteins_filtered = pd.read_csv('/content/all_proteins_filtered.csv', index_col=0)\n",
        "all_proteins_rapid = pd.read_csv('/content/all_proteins_rapid.csv', index_col=0)\n",
        "all_proteins_disordered = pd.read_csv('/content/all_proteins_disordered.csv', index_col=0)"
      ],
      "metadata": {
        "id": "-i89P51dFOnU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading cluster dataframes"
      ],
      "metadata": {
        "id": "G_0gyDTZfABh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interesting_clusters = pd.read_csv('/content/interesting_clusters.csv', index_col=0)\n",
        "disordered_clusters = pd.read_csv('/content/disordered_clusters.csv', index_col=0)"
      ],
      "metadata": {
        "id": "7zAjdsule_e3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading RAPID_disorder values"
      ],
      "metadata": {
        "id": "1ycexCSdJGh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rapid_disorder_values = pd.read_csv('RAPID_disorder_values.csv', index_col=0)"
      ],
      "metadata": {
        "id": "9BGAYQdRJLEA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting UniProt IDs"
      ],
      "metadata": {
        "id": "RhKK8S_2JazH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tepura has NCBI taxonomy IDs, but we need UniProt proteome IDs. We can get them using UniProt REST API search"
      ],
      "metadata": {
        "id": "eRusyqinJwYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniprot_jsons = []\n",
        "failures = []\n",
        "\n",
        "# loop through the taxonomy IDs and retrieve proteome data\n",
        "for tax_id in tqdm(tempura['taxonomy_id']):\n",
        "  # define the UniProt API URL\n",
        "  url = f'https://rest.uniprot.org/proteomes/stream?format=json&query=%28%28taxonomy_id%3A{tax_id}%29%29'\n",
        "  # send an HTTP GET request to the UniProt API\n",
        "  response = requests.get(url)\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "    # save JSON\n",
        "    uniprot_jsons.append(response.json())\n",
        "  else:\n",
        "    failures.append(tax_id)\n",
        "    uniprot_jsons.append({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUv2C0fB74hi",
        "outputId": "cde8bcff-694e-43c4-f4ea-859c06e2b47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 893/893 [08:24<00:00,  1.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In many cases we get mre than one search result for one taxonomy ID. We need to check each search result and only keep the UniProt ID that has the same taxonomy ID as Tempura"
      ],
      "metadata": {
        "id": "Mhqi7sv7KBIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate empty list to save UniProt IDs\n",
        "uniprot_ids = []\n",
        "\n",
        "# iterate through JSON results\n",
        "for i, jsn in enumerate(uniprot_jsons):\n",
        "  # get results\n",
        "  results = jsn['results']\n",
        "  # get candidate UniProt IDs and corresponding taxonomy IDs\n",
        "  u_ids = [r['id'] for r in results]\n",
        "  t_ids = [r['taxonomy']['taxonId'] for r in results]\n",
        "  # make a dictionary of candidate IDs\n",
        "  results_dict = {k:v for k, v in zip(t_ids, u_ids)}\n",
        "  # get actual taxonomy ID\n",
        "  taxonomy_id = tempura.loc[i, 'taxonomy_id']\n",
        "  # save correct UniProt ID\n",
        "  try:\n",
        "    uniprot_ids.append(results_dict[taxonomy_id])\n",
        "  except:\n",
        "    # no correct ID found\n",
        "    uniprot_ids.append(None)"
      ],
      "metadata": {
        "id": "IfXFBMziEcq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now drop any Tempura rows with no available UniProt IDs and store the result"
      ],
      "metadata": {
        "id": "1nRNvH05KPdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempura['uniprot_id'] = uniprot_ids"
      ],
      "metadata": {
        "id": "Ee6rRDqIGjXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tempura.dropna(subset='uniprot_id', inplace=True)"
      ],
      "metadata": {
        "id": "ISs1RefSGjUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tempura.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "TC3ydi-fIc3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tempura.to_csv('tempura_bacteria_uniprot.csv')"
      ],
      "metadata": {
        "id": "R009ua3BIc09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading UniProt proteomes"
      ],
      "metadata": {
        "id": "F2yc99UUKY7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir proteomes"
      ],
      "metadata": {
        "id": "4THt0_CpLwBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tempura.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVyK87LaIcy4",
        "outputId": "927f0ac4-9441-4025-e360-53546f963949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 680 entries, 0 to 679\n",
            "Data columns (total 21 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   genus_and_species      680 non-null    object \n",
            " 1   taxonomy_id            680 non-null    int64  \n",
            " 2   strain                 680 non-null    object \n",
            " 3   superkingdom           680 non-null    object \n",
            " 4   phylum                 680 non-null    object \n",
            " 5   class                  678 non-null    object \n",
            " 6   order                  673 non-null    object \n",
            " 7   family                 662 non-null    object \n",
            " 8   genus                  675 non-null    object \n",
            " 9   assembly_or_accession  680 non-null    object \n",
            " 10  Genome_GC              651 non-null    float64\n",
            " 11  Genome_size            680 non-null    float64\n",
            " 12  16S_accssion           680 non-null    object \n",
            " 13  16S_GC                 680 non-null    float64\n",
            " 14  Tmin                   680 non-null    float64\n",
            " 15  Topt_ave               680 non-null    float64\n",
            " 16  Topt_low               258 non-null    float64\n",
            " 17  Topt_high              258 non-null    float64\n",
            " 18  Tmax                   680 non-null    float64\n",
            " 19  Tmax_Tmin              680 non-null    float64\n",
            " 20  uniprot_id             680 non-null    object \n",
            "dtypes: float64(9), int64(1), object(11)\n",
            "memory usage: 111.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "failures = []\n",
        "\n",
        "for i in tqdm(tempura.index):\n",
        "  # make file path and get UniProt ID\n",
        "  species = tempura.loc[i, 'genus_and_species'].replace(' ', '_')\n",
        "  fasta_file_path = f'/content/proteomes/{species}.fasta'\n",
        "  id = tempura.loc[i, 'uniprot_id']\n",
        "  # define the UniProt API URL to retrieve FASTA data\n",
        "  url = f'https://rest.uniprot.org/uniprotkb/stream?format=fasta&query=%28%28proteome%3A{id}%29%29'\n",
        "  # send an HTTP GET request to the UniProt API to get FASTA data\n",
        "  response = requests.get(url)\n",
        "  # check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "    # save the FASTA data to a file\n",
        "    with open(fasta_file_path, 'w') as fasta_file:\n",
        "      fasta_file.write(response.text)\n",
        "  else:\n",
        "    failures.append(id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLhoQR5MLTNR",
        "outputId": "b22356ae-b178-4e8f-ab71-d258be86fd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 680/680 [56:33<00:00,  4.99s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "failures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTXxlgftLTJ5",
        "outputId": "92cda7ed-462b-4960-97fe-e42aff9bc618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/proteomes.zip /content/proteomes -i '*.fasta'\n",
        "from google.colab import files\n",
        "files.download('/content/proteomes.zip')"
      ],
      "metadata": {
        "id": "2d0ec6lWzU5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a DataFrame with all sequences"
      ],
      "metadata": {
        "id": "y1SgrhJ7y4Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_proteins = pd.DataFrame(columns=['ID', 'Sequence', 'Length', 'Species'])"
      ],
      "metadata": {
        "id": "24wNr5uoy_GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for species in tqdm(tempura['genus_and_species']):\n",
        "  filename = species.replace(' ', '_') + '.fasta'\n",
        "  df = read_fasta(f'/content/proteomes/{filename}')\n",
        "  df['Species'] = species\n",
        "  all_proteins = pd.concat([all_proteins, df], ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNo-CGEpwClO",
        "outputId": "752799ed-3ccc-4545-fcb4-4295e82f0182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 680/680 [01:02<00:00, 10.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_proteins.to_csv('all_proteins.csv')"
      ],
      "metadata": {
        "id": "av-YifuThIyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering to only keep species with at least 1000 proteins"
      ],
      "metadata": {
        "id": "-TYts9fc1MlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# group the DataFrame by the 'species' column and count the number of records for each species\n",
        "species_counts = all_proteins['Species'].value_counts()\n",
        "# filter the species with more than 1000 records\n",
        "selected_species = species_counts[species_counts >= 1000].index\n",
        "# create a new DataFrame that only includes the selected species\n",
        "all_proteins_filtered = all_proteins[all_proteins['Species'].isin(selected_species)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "fJr_obyrhIwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove species that don't have 1000 records from Tempura"
      ],
      "metadata": {
        "id": "l-z2s0h38P95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempura = tempura[tempura['genus_and_species'].isin(selected_species)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Isi8KdohhItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tempura.to_csv('tempura_filtered.csv')"
      ],
      "metadata": {
        "id": "yB_1pNdrGjSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving combined FASTA files for disorder calculations"
      ],
      "metadata": {
        "id": "qqW8x4sh82ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/combined_fastas"
      ],
      "metadata": {
        "id": "XOinz6NpNVU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the maximum sequences per file\n",
        "max_sequences_per_file = 75000\n",
        "\n",
        "# split the DataFrame into chunks of max_sequences_per_file and save as FASTA files\n",
        "for i, chunk in enumerate(range(0, len(all_proteins_filtered), max_sequences_per_file)):\n",
        "  chunk_df = all_proteins_filtered.iloc[chunk:chunk + max_sequences_per_file]\n",
        "  # create a FASTA file for the chunk\n",
        "  fasta_file_path = f'/content/combined_fastas/output_{i+1}.fasta'\n",
        "  with open(fasta_file_path, 'w') as fasta_file:\n",
        "    for _, row in chunk_df.iterrows():\n",
        "      id = row['ID']\n",
        "      seq = row['Sequence']\n",
        "      fasta_file.write(f'>{id}\\n{seq}\\n')"
      ],
      "metadata": {
        "id": "Zgr25_d38xA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/combined_fastas.zip /content/combined_fastas -i '*.fasta'\n",
        "from google.colab import files\n",
        "files.download('/content/combined_fastas.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "xhAyELGINZpB",
        "outputId": "7104042e-0649-4dd1-dae1-0de17f4f8197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/combined_fastas/output_9.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_12.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_10.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_4.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_2.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_5.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_3.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_8.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_1.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_6.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_16.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_7.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_13.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_17.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_11.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_15.fasta (deflated 43%)\n",
            "  adding: content/combined_fastas/output_14.fasta (deflated 43%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_552fd38d-0acf-4559-bb62-d3173f316719\", \"combined_fastas.zip\", 232911944)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}